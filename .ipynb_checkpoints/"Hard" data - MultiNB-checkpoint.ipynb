{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"HARD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dictionary for each type of HARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('new_train/hard.cor') as f:\n",
    "    d = {'HARD1':[], 'HARD2':[], 'HARD3':[]}\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        m = re.search(\"<s>(.*)<\\/s>\", line)\n",
    "        if m:\n",
    "            m2 = re.search(\"<tag \\\"(.*)\\\">(.*)<\\/>\", line)\n",
    "            if m2:\n",
    "                meaning = m2.group(1)\n",
    "                word = m2.group(2)\n",
    "                sentence = m.group(1)\n",
    "                sentence = sentence.replace('<s>', '')\n",
    "                sentence = sentence.replace('</s>', '')\n",
    "                sentence = sentence.replace('<p>', '')\n",
    "                sentence = sentence.replace('</p>', '')\n",
    "                sentence = sentence.replace('<@>', '')\n",
    "                sentence = sentence.replace(m2.group(0), '')\n",
    "                d[meaning].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3455\n",
      "502\n",
      "376\n"
     ]
    }
   ],
   "source": [
    "print len(d['HARD1'])\n",
    "print len(d['HARD2'])\n",
    "print len(d['HARD3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"INTEREST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('new_train/interest.cor') as f:\n",
    "    d = {}\n",
    "    for i in xrange(6):\n",
    "        key = 'interest_{}'.format(i+1)\n",
    "        d[key] = []\n",
    "    for line in f.readlines():\n",
    "        m = re.search(\"<s>(.*)<\\/s>\", line)\n",
    "        if m:\n",
    "            m2 = re.search(\"<tag \\\"(.*)\\\">(.*)<\\/>\", line)\n",
    "            if m2:\n",
    "                meaning = m2.group(1)\n",
    "                word = m2.group(2)\n",
    "                sentence = m.group(1)\n",
    "                sentence = sentence.replace(m2.group(0), '')\n",
    "                d[meaning].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interest_5 500\n",
      "interest_4 178\n",
      "interest_6 1252\n",
      "interest_1 361\n",
      "interest_3 66\n",
      "interest_2 11\n"
     ]
    }
   ],
   "source": [
    "for key in d.keys():\n",
    "    print key, len(d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_documents = [sentence for value in d.values() for sentence in value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a documents of all sentences, regardless of meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_documents = [sentence for value in d.values() for sentence in value]\n",
    "# [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lem(documents):\n",
    "    lem_documents = []\n",
    "    for doc in documents:\n",
    "        no_tag_words = [w[:-3] for w in gensim.utils.lemmatize(doc)]\n",
    "        lem_documents.append(' '.join(no_tag_words)) \n",
    "    return lem_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lem_train_documents = lem(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bolduc vice chairman grace co hold energy service company be elect director'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_train_documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Tfidf(documents):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3)).fit(documents)\n",
    "    vectors = vectorizer.transform(documents)\n",
    "    return vectors, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectors, vectorizer = Tfidf(lem_train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2368x50531 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 83625 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resample (don't need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hard1 = list(np.random.choice(d['HARD1'], 700, replace=False))1 = d['HARD1']\n",
    "i1 = d['interest_1']\n",
    "i2 = d['interest_2']\n",
    "i3 = d['interest_3']\n",
    "i4 = d['interest_4']\n",
    "i5 = d['interest_5']\n",
    "i6 = d['interest_6']\n",
    "\n",
    "\n",
    "resamp = i1+i2+i3+i4+i5+i6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368 2368\n",
      " ``  it  's horrible to say , but  it  's unfortunate that  earthquake was n't  in  phoenix  --  it  might have knocked out  some  of  our empty buildings  , '' said  c.w. jackson  ,  a prominent arizona businessman  with      in  real estate  , banking and  many other businesses  . \n",
      "-----\n",
      " he  predicts  a downward move  in  dollar-mark trade  and  a less dramatic slip  in  dollar-yen  , noting that  there  continues to be  a large pool  of  japanese investor     in  u.s. securities  ,  which  could provide  a solid base  for  the dollar  at around  140 yen  . \n"
     ]
    }
   ],
   "source": [
    "# train_documents == resamp\n",
    "print len(train_documents), len(resamp)\n",
    "print train_documents[100]\n",
    "print '-----'\n",
    "print resamp[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors, vectorizer = Tfidf(resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2368x58122 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 92159 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1 = np.repeat('INTEREST1', len(i1))\n",
    "y2 = np.repeat('INTEREST2', len(i2))\n",
    "y3 = np.repeat('INTEREST3', len(i3))\n",
    "y4 = np.repeat('INTEREST4', len(i4))\n",
    "y5 = np.repeat('INTEREST5', len(i5))\n",
    "y6 = np.repeat('INTEREST6', len(i6))\n",
    "\n",
    "y = np.concatenate((y1, y2, y3, y4, y5, y6), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.12, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB(alpha= 0.12)\n",
    "NB.fit(vectors,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTEREST6'], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"I work hard\"\n",
    "vector = vectorizer.transform([s])\n",
    "NB.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_NB(sentence, vectorizer, nb):\n",
    "    vector = vectorizer.transform([sentence]) # use the vectorizer from training\n",
    "    return nb.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTEREST6'], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_NB(s, vectorizer, NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARD1 score:  3454 / 3455\n",
      "HARD2 score:  495 / 502\n",
      "HARD3 score:  376 / 376\n"
     ]
    }
   ],
   "source": [
    "# Hard data\n",
    "pred_score_hard1, pred_score_hard2, pred_score_hard3 = 0, 0, 0\n",
    "\n",
    "for sent in d['HARD1']:\n",
    "\n",
    "    if predict_NB(sent, vectorizer, NB) == 'HARD1':\n",
    "        pred_score_hard1 += 1\n",
    "print \"HARD1 score: \", pred_score_hard1, '/', len(d['HARD1'])\n",
    "\n",
    "for sent in d['HARD2']:\n",
    "    if predict_NB(sent, vectorizer, NB) == 'HARD2':\n",
    "        pred_score_hard2 += 1\n",
    "print \"HARD2 score: \", pred_score_hard2, '/', len(d['HARD2'])\n",
    "\n",
    "for sent in d['HARD3']:\n",
    "    if predict_NB(sent, vectorizer, NB) == 'HARD3':\n",
    "        pred_score_hard3 += 1\n",
    "print \"HARD3 score: \", pred_score_hard3, '/', len(d['HARD3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interest_1 score:  0 / 361\n"
     ]
    }
   ],
   "source": [
    "# Interest data\n",
    "pred_score_hard1, pred_score_hard2, pred_score_hard3 = 0, 0, 0\n",
    "\n",
    "for sent in d['interest_1']:\n",
    "\n",
    "    if predict_NB(sent, vectorizer, NB) == 'interest_1':\n",
    "        pred_score_hard1 += 1\n",
    "print \"interest_1 score: \", pred_score_hard1, '/', len(d['interest_1'])\n",
    "\n",
    "# for sent in d['HARD2']:\n",
    "#     if predict_NB(sent, vectorizer, NB) == 'HARD2':\n",
    "#         pred_score_hard2 += 1\n",
    "# print \"HARD2 score: \", pred_score_hard2, '/', len(d['HARD2'])\n",
    "\n",
    "# for sent in d['HARD3']:\n",
    "#     if predict_NB(sent, vectorizer, NB) == 'HARD3':\n",
    "#         pred_score_hard3 += 1\n",
    "# print \"HARD3 score: \", pred_score_hard3, '/', len(d['HARD3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77316736,  0.78947368,  0.78031878])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(NB, vectors, y, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.77787688,  0.78712895,  0.782662  ])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(NB, vectors, y, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/datascientist/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.77316736,  0.78947368,  0.78031878])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(NB, vectors, y, scoring='recall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
